{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea498ec-8540-4a27-9e2c-7ad50f9d2bcd",
   "metadata": {},
   "source": [
    "# Breast Cancer Tumor Classification (Malignant or Benign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04546b5-5c94-4d32-884e-2ad01c22abb1",
   "metadata": {},
   "source": [
    "We utilize an anonymized dataset of Breast Cancer tumor cell nucei data computed from fine needle aspirate (FMA) of breast mass. This data was originally provided by the University of Wisconsin and obtained here from the University of California: Irvine machine learning repository.\n",
    "https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1922d6-cccf-4767-ac68-de10976fc9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6f9ae7-fbb9-4c42-bd3a-4c88a3d944fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data_raw = pd.read_csv(\"BreastCancerDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337e713a-a0b6-41b3-a6c1-1364a415301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>...</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
       "0    842302    17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
       "1    842517    20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
       "2  84300903    19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
       "3  84348301    11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
       "4  84358402    20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
       "5    843786    12.45     15.70       82.57   477.1      0.12780       0.17000   \n",
       "6    844359    18.25     19.98      119.60  1040.0      0.09463       0.10900   \n",
       "7  84458202    13.71     20.83       90.20   577.9      0.11890       0.16450   \n",
       "8    844981    13.00     21.82       87.50   519.8      0.12730       0.19320   \n",
       "9  84501001    12.46     24.04       83.97   475.9      0.11860       0.23960   \n",
       "\n",
       "   concavity1  concave_points1  symmetry1  ...  texture3  perimeter3   area3  \\\n",
       "0     0.30010          0.14710     0.2419  ...     17.33      184.60  2019.0   \n",
       "1     0.08690          0.07017     0.1812  ...     23.41      158.80  1956.0   \n",
       "2     0.19740          0.12790     0.2069  ...     25.53      152.50  1709.0   \n",
       "3     0.24140          0.10520     0.2597  ...     26.50       98.87   567.7   \n",
       "4     0.19800          0.10430     0.1809  ...     16.67      152.20  1575.0   \n",
       "5     0.15780          0.08089     0.2087  ...     23.75      103.40   741.6   \n",
       "6     0.11270          0.07400     0.1794  ...     27.66      153.20  1606.0   \n",
       "7     0.09366          0.05985     0.2196  ...     28.14      110.60   897.0   \n",
       "8     0.18590          0.09353     0.2350  ...     30.73      106.20   739.3   \n",
       "9     0.22730          0.08543     0.2030  ...     40.68       97.65   711.4   \n",
       "\n",
       "   smoothness3  compactness3  concavity3  concave_points3  symmetry3  \\\n",
       "0       0.1622        0.6656      0.7119           0.2654     0.4601   \n",
       "1       0.1238        0.1866      0.2416           0.1860     0.2750   \n",
       "2       0.1444        0.4245      0.4504           0.2430     0.3613   \n",
       "3       0.2098        0.8663      0.6869           0.2575     0.6638   \n",
       "4       0.1374        0.2050      0.4000           0.1625     0.2364   \n",
       "5       0.1791        0.5249      0.5355           0.1741     0.3985   \n",
       "6       0.1442        0.2576      0.3784           0.1932     0.3063   \n",
       "7       0.1654        0.3682      0.2678           0.1556     0.3196   \n",
       "8       0.1703        0.5401      0.5390           0.2060     0.4378   \n",
       "9       0.1853        1.0580      1.1050           0.2210     0.4366   \n",
       "\n",
       "   fractal_dimension3  Diagnosis  \n",
       "0             0.11890          M  \n",
       "1             0.08902          M  \n",
       "2             0.08758          M  \n",
       "3             0.17300          M  \n",
       "4             0.07678          M  \n",
       "5             0.12440          M  \n",
       "6             0.08368          M  \n",
       "7             0.11510          M  \n",
       "8             0.10720          M  \n",
       "9             0.20750          M  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f16ebc5-5479-465d-82a4-fa87a7f3ca06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7fc43-5200-460f-ba4b-1a77848e20e8",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a340a7d-804b-4f3f-abb5-caf8d9af8c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>...</th>\n",
       "      <th>radius3</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID     radius1    texture1  perimeter1        area1  \\\n",
       "count  5.690000e+02  569.000000  569.000000  569.000000   569.000000   \n",
       "mean   3.037183e+07   14.127292   19.289649   91.969033   654.889104   \n",
       "std    1.250206e+08    3.524049    4.301036   24.298981   351.914129   \n",
       "min    8.670000e+03    6.981000    9.710000   43.790000   143.500000   \n",
       "25%    8.692180e+05   11.700000   16.170000   75.170000   420.300000   \n",
       "50%    9.060240e+05   13.370000   18.840000   86.240000   551.100000   \n",
       "75%    8.813129e+06   15.780000   21.800000  104.100000   782.700000   \n",
       "max    9.113205e+08   28.110000   39.280000  188.500000  2501.000000   \n",
       "\n",
       "       smoothness1  compactness1  concavity1  concave_points1   symmetry1  \\\n",
       "count   569.000000    569.000000  569.000000       569.000000  569.000000   \n",
       "mean      0.096360      0.104341    0.088799         0.048919    0.181162   \n",
       "std       0.014064      0.052813    0.079720         0.038803    0.027414   \n",
       "min       0.052630      0.019380    0.000000         0.000000    0.106000   \n",
       "25%       0.086370      0.064920    0.029560         0.020310    0.161900   \n",
       "50%       0.095870      0.092630    0.061540         0.033500    0.179200   \n",
       "75%       0.105300      0.130400    0.130700         0.074000    0.195700   \n",
       "max       0.163400      0.345400    0.426800         0.201200    0.304000   \n",
       "\n",
       "       ...     radius3    texture3  perimeter3        area3  smoothness3  \\\n",
       "count  ...  569.000000  569.000000  569.000000   569.000000   569.000000   \n",
       "mean   ...   16.269190   25.677223  107.261213   880.583128     0.132369   \n",
       "std    ...    4.833242    6.146258   33.602542   569.356993     0.022832   \n",
       "min    ...    7.930000   12.020000   50.410000   185.200000     0.071170   \n",
       "25%    ...   13.010000   21.080000   84.110000   515.300000     0.116600   \n",
       "50%    ...   14.970000   25.410000   97.660000   686.500000     0.131300   \n",
       "75%    ...   18.790000   29.720000  125.400000  1084.000000     0.146000   \n",
       "max    ...   36.040000   49.540000  251.200000  4254.000000     0.222600   \n",
       "\n",
       "       compactness3  concavity3  concave_points3   symmetry3  \\\n",
       "count    569.000000  569.000000       569.000000  569.000000   \n",
       "mean       0.254265    0.272188         0.114606    0.290076   \n",
       "std        0.157336    0.208624         0.065732    0.061867   \n",
       "min        0.027290    0.000000         0.000000    0.156500   \n",
       "25%        0.147200    0.114500         0.064930    0.250400   \n",
       "50%        0.211900    0.226700         0.099930    0.282200   \n",
       "75%        0.339100    0.382900         0.161400    0.317900   \n",
       "max        1.058000    1.252000         0.291000    0.663800   \n",
       "\n",
       "       fractal_dimension3  \n",
       "count          569.000000  \n",
       "mean             0.083946  \n",
       "std              0.018061  \n",
       "min              0.055040  \n",
       "25%              0.071460  \n",
       "50%              0.080040  \n",
       "75%              0.092080  \n",
       "max              0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Summary\n",
    "breast_cancer_data_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b64411-399c-48fa-ad51-f212ad14843f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1',\n",
       "       'compactness1', 'concavity1', 'concave_points1', 'symmetry1',\n",
       "       'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2',\n",
       "       'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
       "       'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3',\n",
       "       'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
       "       'symmetry3', 'fractal_dimension3', 'Diagnosis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e072fd07-d83e-4ec4-a0fa-3c6d68c88072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with \"NaN\" or no value in any field\n",
    "breast_cancer_data_nonan = breast_cancer_data_raw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c1bdd6-8edf-4007-8aa5-3a8835494572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(breast_cancer_data_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c08b68d-9649-4cc6-b3e8-41ed186c20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = breast_cancer_data_nonan[breast_cancer_data_nonan.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4781b6-eafd-4bd3-b9d8-f2433f971fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>...</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, radius1, texture1, perimeter1, area1, smoothness1, compactness1, concavity1, concave_points1, symmetry1, fractal_dimension1, radius2, texture2, perimeter2, area2, smoothness2, compactness2, concavity2, concave_points2, symmetry2, fractal_dimension2, radius3, texture3, perimeter3, area3, smoothness3, compactness3, concavity3, concave_points3, symmetry3, fractal_dimension3, Diagnosis]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2968e7ff-def5-4e8a-870b-906c7f6e2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/fjy4cptn0jb_d8mlggpd9rj00000gn/T/ipykernel_2120/1500849987.py:2: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  breast_cancer_data_tofloat = breast_cancer_data_nonan.apply(lambda col: pd.to_numeric(col, errors='ignore'))\n"
     ]
    }
   ],
   "source": [
    "# Typecast all numbers to float or int\n",
    "breast_cancer_data_tofloat = breast_cancer_data_nonan.apply(lambda col: pd.to_numeric(col, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "593ee38d-625f-4828-97d8-df9586c0f102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/fjy4cptn0jb_d8mlggpd9rj00000gn/T/ipykernel_2120/595094664.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  breast_cancer_data_tofloat['Diagnosis'] = breast_cancer_data_tofloat['Diagnosis'].replace(\"B\", 1)\n"
     ]
    }
   ],
   "source": [
    "# Manually enforce one-hot encoding for categorical target variable\n",
    "breast_cancer_data_tofloat['Diagnosis'] = breast_cancer_data_tofloat['Diagnosis'].replace(\"M\", 0)\n",
    "breast_cancer_data_tofloat['Diagnosis'] = breast_cancer_data_tofloat['Diagnosis'].replace(\"B\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42c9e7c1-674e-43ff-81b8-a0318eb1ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data_prelimtrain = breast_cancer_data_tofloat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c1c6349-0062-4fd3-8dcd-89a254ff1945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(breast_cancer_data_prelimtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92758431-a594-4acd-ad29-ea1e9fe97ef7",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9402991a-9f37-49b2-b188-440f34a478d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37397c7f-d226-4089-8812-75d2b3002bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAIhCAYAAABUopIpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVQklEQVR4nO3df3xP9f//8fvLbK/ZT5vNXhszym9DRWQU83t+l0JKJryVHyUkPzO9RUmovNNvKyneCu9+oPz+0aghoSTKz4/N/NyMtbGd7x8ue3172cb2Ml4ct+vlci4X55zneZ7Hee21s7vzep7zshiGYQgAAAAwgRKuLgAAAAAoLoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbmEJ8fLwsFot98vT0lM1mU3R0tKZMmaKUlJQ828TFxclisbig2usvNjZWFStWLJa+KlasaH9dS5QoIX9/f9WoUUNPPPGEvv/++3y3sVgsiouLK9J+li5dWuRt8ttX7nthy5YtRe6rIEePHlVcXJy2b9+eZ50r30cVK1ZUbGxssfV3+e+RxWJRcHCwmjVrpm+++abY9nM9/Pbbb4qLi9OBAweKtN2OHTvUp08fVapUSZ6envLx8dE999yjqVOn6tSpU9en2JtA7vs2d/Ly8lL58uXVpk0bvfXWWzp79qzTfSckJCguLk5nzpwpvoKvgbPnFty6CLcwlTlz5mjTpk1asWKF/vOf/+iuu+7Sq6++qho1amjlypUObfv166dNmza5qNLra/z48Vq8eHGx9de4cWNt2rRJCQkJ+vLLLzV48GDt379fbdq00cMPP6wLFy44tN+0aZP69etXpH0sXbpUEydOLHJtzuyrqI4ePaqJEyfmG25d+T5avHixxo8fX+z95v4eJSQk6L333pObm5s6duyor7/+utj3VVx+++03TZw4sUjh9v3331e9evWUmJio559/XsuXL9fixYv1yCOP6J133lHfvn2vX8E3ieXLl2vTpk1avny5pk2bpgoVKmjkyJGqVauWfvnlF6f6TEhI0MSJE2+qcOvMuQW3rpKuLgAoTpGRkapfv759vmvXrnruuefUpEkTPfTQQ9q7d69CQkIkSeXLl1f58uVdVep1deeddxZrf6VLl9Z9991nn2/ZsqUGDRqkuLg4TZw4UePGjdOrr75qX//PtteDYRj6+++/VapUqeu+r6tx5fvo7rvvvi79Xv571LZtWwUEBOjzzz9Xx44dC9wuOztbFy9elNVqvS51FadNmzbp6aefVqtWrbRkyRKHmlu1aqXhw4dr+fLlLqzw2p0/f15eXl5XbFOvXj0FBQXZ53v06KHBgweradOm6tSpk/74449b4ucJ/BNXbmF6FSpU0Ouvv66zZ8/q3XfftS/P7+PkBQsWqHXr1goNDVWpUqVUo0YNjRo1SufOncvT7/vvv6+qVavKarWqZs2a+uyzz/IMBzhw4IAsFoumTZum6dOnq1KlSvLx8VGjRo20efPmPH1+9dVXatSokby8vOTr66tWrVrluSp4/Phx/etf/1J4eLisVquCg4PVuHFjhyvT+Q1LWLhwoRo2bCh/f395eXnpjjvu0JNPPlmUlzKPuLg41apVS7NmzdLff/9tX375UIHz589rxIgR9o9+AwMDVb9+fX3++ef2ev/zn//Yt82dcq/CWSwWDR48WO+8845q1Kghq9Wqjz/+ON995Tp9+rT69OmjwMBAeXt7q2PHjvrrr78c2hT0sX6zZs3UrFkzSdLatWt17733SpL69Oljry13n/m9j3JycjR16lRVr15dVqtVZcuW1RNPPKEjR47k2U9kZKQSExN1//33238ur7zyinJycgp+4Quof+3atbJYLPr88881duxYhYWFyc/PTy1bttSePXuu2l9BPD095eHhIXd3d/uy3Pf21KlTNWnSJFWqVElWq1Vr1qyRJG3ZskWdOnVSYGCgPD09dffdd+u///2vQ7/Hjx/XwIEDVbNmTfn4+Khs2bJq3ry5NmzYkKeG2bNnq27duvLx8ZGvr6+qV6+uMWPGSLo0nOKRRx6RJEVHR9t/RvHx8QUe0+TJk2WxWPTee+/lG948PDzUqVMn+3xhzw2xsbHy8fHRvn371K5dO/n4+Cg8PFzDhw9XZmamQ9vMzEy99NJLqlGjhjw9PVWmTBlFR0crISHB3sYwDL399tu66667VKpUKQUEBOjhhx/O817OfS+tX79eUVFR8vLycvr3u27duho7dqwOHTqkBQsW2JevWLFCnTt3Vvny5eXp6anKlStrwIABOnHihL1NXFycnn/+eUlSpUqV7D+LtWvXFul1/Ouvv9SjRw+FhYXJarUqJCRELVq0yPPpyYIFC9SoUSN5e3vLx8dHbdq00c8//2xff7VzC8yJK7e4LbRr105ubm5av379Fdvt3btX7dq109ChQ+Xt7a3ff/9dr776qn766SetXr3a3u69997TgAED1LVrV82YMUOpqamaOHFinj9euf7zn/+oevXqmjlzpqRLwwbatWun/fv3y9/fX5L02Wef6bHHHlPr1q31+eefKzMzU1OnTlWzZs20atUqNWnSRJLUq1cvbdu2TS+//LKqVq2qM2fOaNu2bTp58mSBx7Vp0yZ1795d3bt3V1xcnDw9PXXw4EGHY3JWx44d9corr2jLli32Gi83bNgwzZ07V5MmTdLdd9+tc+fOadeuXfaax48fr3PnzumLL75wCPOhoaH2fy9ZskQbNmzQiy++KJvNprJly16xrr59+6pVq1b67LPPdPjwYY0bN07NmjXTjh07VLp06UIf3z333KM5c+aoT58+GjdunNq3by9JV7xa+/TTT+u9997T4MGD1aFDBx04cEDjx4/X2rVrtW3bNocrZcnJyXrsscc0fPhwTZgwQYsXL9bo0aMVFhamJ554otB1/tOYMWPUuHFjffDBB0pLS9MLL7ygjh07avfu3XJzc7vq9rlXYA3D0LFjx/Taa6/p3Llz6tmzZ562b775pqpWrapp06bJz89PVapU0Zo1a9S2bVs1bNhQ77zzjvz9/TV//nx1795d58+ftwfy3DGtEyZMkM1mU3p6uhYvXmx/z+f+B2P+/PkaOHCghgwZomnTpqlEiRLat2+ffvvtN0lS+/btNXnyZI0ZM0b/+c9/dM8990gq+BOM7OxsrV69WvXq1VN4eHihXtPCnhsk6cKFC+rUqZP69u2r4cOHa/369fr3v/8tf39/vfjii5KkixcvKiYmRhs2bNDQoUPVvHlzXbx4UZs3b9ahQ4cUFRUlSRowYIDi4+P1zDPP6NVXX9WpU6f00ksvKSoqSr/88ov9kyhJSkpK0uOPP66RI0dq8uTJKlHC+etXnTp10siRI7V+/Xr7+/DPP/9Uo0aN1K9fP/n7++vAgQOaPn26mjRpop07d8rd3V39+vXTqVOn9NZbb2nRokX23+GaNWsW6XVs166dsrOzNXXqVFWoUEEnTpxQQkKCw1CHyZMna9y4cfbfzaysLL322mu6//779dNPP6lmzZqFOrfAhAzABObMmWNIMhITEwtsExISYtSoUcM+P2HCBONKvwI5OTnGhQsXjHXr1hmSjF9++cUwDMPIzs42bDab0bBhQ4f2Bw8eNNzd3Y2IiAj7sv379xuSjNq1axsXL160L//pp58MScbnn39u7zMsLMyoXbu2kZ2dbW939uxZo2zZskZUVJR9mY+PjzF06NArvh69e/d2qGPatGmGJOPMmTNX3C4/ERERRvv27QtcP3v2bEOSsWDBAvsyScaECRPs85GRkUaXLl2uuJ9BgwYV+POQZPj7+xunTp3Kd90/95X7XnjwwQcd2v3www+GJGPSpEkOx9a7d+88fTZt2tRo2rSpfT4xMdGQZMyZMydP28vfR7t37zYkGQMHDnRo9+OPPxqSjDFjxjjsR5Lx448/OrStWbOm0aZNmzz7utzl9a9Zs8aQZLRr186h3X//+19DkrFp06Yr9pf72l0+Wa1W4+2333Zom/vevvPOO42srCyHddWrVzfuvvtu48KFCw7LO3ToYISGhjq8x//p4sWLxoULF4wWLVo4/PwGDx5slC5d+oq1L1y40JBkrFmz5ortDMMwkpOTDUlGjx49rto2PwWdGwzj0u+eJOO///2vwzbt2rUzqlWrZp//5JNPDEnG+++/X+B+Nm3aZEgyXn/9dYflhw8fNkqVKmWMHDnSviz3vbRq1apCHUPu+/b48eP5rs/IyDAkGTExMfmuz30NDh48aEgy/ve//9nXvfbaa4YkY//+/VesoaDX8cSJE4YkY+bMmQVue+jQIaNkyZLGkCFDHJafPXvWsNlsRrdu3ezLrnRugTkxLAG3DcMwrtrmr7/+Us+ePWWz2eTm5iZ3d3c1bdpUkrR7925J0p49e5ScnKxu3bo5bFuhQgU1btw4337bt2/vcMWsTp06kqSDBw/a+zx69Kh69erlcLXFx8dHXbt21ebNm3X+/HlJUoMGDRQfH69JkyZp8+bNeW7myk/ux+rdunXTf//7X/3f//3fVbcprMK8rg0aNNCyZcs0atQorV27VhkZGUXeT/PmzRUQEFDo9o899pjDfFRUlCIiIuwfm18vuf1fPtyhQYMGqlGjhlatWuWw3GazqUGDBg7L6tSpY39vOOOfH6fn9iep0H1+8sknSkxMVGJiopYtW6bevXtr0KBBmjVrVr77+udwhX379un333+3v/4XL160T+3atVNSUpLDEIl33nlH99xzjzw9PVWyZEm5u7tr1apV9t836dJrd+bMGT366KP63//+5/Ax+I1SmHNDLovFkmds8uU/02XLlsnT0/OKQwe++eYbWSwWPf744w6vo81mU926de0f9ecKCAhQ8+bNr/FIL8nv9zolJUVPPfWUwsPD7T+riIgISXlfg4IU5nUMDAzUnXfeqddee03Tp0/Xzz//nGeYznfffaeLFy/qiSeecHhtPD091bRp0zyvDW4vhFvcFs6dO6eTJ08qLCyswDbp6em6//779eOPP2rSpElau3atEhMTtWjRIkmyB7Lcj9L/+XFgrvyWSVKZMmUc5nPH+F3eZ34flYWFhSknJ0enT5+WdGmMWe/evfXBBx+oUaNGCgwM1BNPPKHk5OQCj+2BBx7QkiVL7H8Mypcvr8jISPuY12uR+wf7Sq/tm2++qRdeeEFLlixRdHS0AgMD1aVLF+3du7fQ+ynqx4g2my3fZVcavlEcrvazvHz/l783pEvvD2f+A1BQn5e/366mRo0aql+/vurXr6+2bdvq3XffVevWrTVy5Mg8d8BffpzHjh2TJI0YMULu7u4O08CBAyXJHk6nT5+up59+Wg0bNtSXX36pzZs3KzExUW3btnWotVevXvroo4908OBBde3aVWXLllXDhg21YsWKwr8o/xAUFCQvLy/t37+/UO0Le27I5eXlJU9PT4dlVqvVYVz68ePHFRYWdsWhA8eOHZNhGAoJCcnzWm7evDlPyC/Oj9ov/73OyclR69attWjRIo0cOVKrVq3STz/9ZL93oDDvrcK+jhaLRatWrVKbNm00depU3XPPPQoODtYzzzxjf0RZ7vvs3nvvzfPaLFiwwCX/AcLNgzG3uC18++23ys7Oto/hy8/q1at19OhRrV271n4lQVKeP+a5wSH35PpPVwqYV5LbZ1JSUp51R48eVYkSJexXLYOCgjRz5kzNnDlThw4d0ldffaVRo0YpJSXlind3d+7cWZ07d1ZmZqY2b96sKVOmqGfPnqpYsaIaNWrkVN2GYejrr7+Wt7e3w931l/P29tbEiRM1ceJEHTt2zH4Vt2PHjvr9998Lta+iPks2v59FcnKyKleubJ/39PTMd5z0iRMnHMbFFsU/f5aXj8s9evSo0/26Wp06dfTdd9/pjz/+cLjSfPnPJff4Ro8erYceeijfvqpVqyZJ+vTTT9WsWTPNnj3bYX1+z1jt06eP+vTpo3Pnzmn9+vWaMGGCOnTooD/++MN+9bCw3Nzc1KJFCy1btkxHjhy56tMuCntuKIrg4GBt3LhROTk5BQbcoKAgWSwWbdiwId+b3i5fVpzPW/7qq68kyX7O3LVrl3755RfFx8erd+/e9nb79u0rdJ9FeR0jIiL04YcfSpL++OMP/fe//1VcXJyysrL0zjvv2N9nX3zxRZF//jA/rtzC9A4dOqQRI0bI399fAwYMKLBd7h+Gy/9g/PMJC9KlP8w2my3Pnd+HDh1yuMu5KKpVq6Zy5crps88+c/g48Ny5c/ryyy/tT1C4XIUKFTR48GC1atVK27ZtK9S+rFarmjZtan901z/vLC6qiRMn6rffftOzzz6b50pVQUJCQhQbG6tHH31Ue/bssQ+3KOrVxauZN2+ew3xCQoIOHjzo8B+cihUraseOHQ7t/vjjjzxPFihKbbkfC3/66acOyxMTE7V79261aNGi0MdwM8m9Sz04OPiK7apVq6YqVarol19+sV/9vXzy9fWVdOl37vLftx07dlzxucHe3t6KiYnR2LFjlZWVpV9//VVS0d8/o0ePlmEY6t+/v7KysvKsv3Dhgv25voU9NxRFTEyM/v777ys+0aFDhw4yDEP/93//l+/rWLt2baf3fyW//PKLJk+erIoVK9qHXxXlNSjoZ+Hs61i1alWNGzdOtWvXtp/n2rRpo5IlS+rPP/8s8H12tXpgXly5hans2rXLPvYqJSVFGzZs0Jw5c+Tm5qbFixdf8Q9zVFSUAgIC9NRTT2nChAlyd3fXvHnz8jzIvESJEpo4caIGDBighx9+WE8++aTOnDmjiRMnKjQ01Kk7lEuUKKGpU6fqscceU4cOHTRgwABlZmbqtdde05kzZ/TKK69IklJTUxUdHa2ePXuqevXq8vX1VWJiopYvX17gVTJJevHFF3XkyBG1aNFC5cuX15kzZ/TGG284jHe7kjNnztg/fjx37pz27Nmj+fPna8OGDerWrdtVH5DesGFDdejQQXXq1FFAQIB2796tuXPnOoT23D/Ur776qmJiYuTm5qY6derIw8OjUK/h5bZs2aJ+/frpkUce0eHDhzV27FiVK1fO/tG4dOnj7scff1wDBw5U165ddfDgQU2dOjXP++TOO+9UqVKlNG/ePNWoUUM+Pj4KCwvLdyhGtWrV9K9//UtvvfWWSpQooZiYGPvTEsLDw/Xcc885dTw3Uu7vkXRpmMWiRYu0YsUKPfjgg6pUqdJVt3/33XcVExOjNm3aKDY2VuXKldOpU6e0e/dubdu2TQsXLpR0Kbz9+9//1oQJE9S0aVPt2bNHL730kipVqmTfvyT1799fpUqVUuPGjRUaGqrk5GRNmTJF/v7+9vHkkZGRki49ycTX11eenp6qVKlSvsM+JKlRo0aaPXu2Bg4cqHr16unpp59WrVq1dOHCBf3888967733FBkZqY4dOxb63FAUjz76qObMmaOnnnpKe/bsUXR0tHJycvTjjz+qRo0a6tGjhxo3bqx//etf6tOnj7Zs2aIHHnhA3t7eSkpK0saNG1W7dm09/fTTTtcgSVu3bpW/v78uXLigo0ePatWqVZo7d67Kli2rr7/+2v77V716dd15550aNWqUDMNQYGCgvv7663yHhuT+Lr/xxhvq3bu33N3dVa1atUK/jjt27NDgwYP1yCOPqEqVKvLw8NDq1au1Y8cOjRo1StKl/5i+9NJLGjt2rP766y/7s5iPHTumn376yf5p0T/rKa5zC24BLruVDShGl9/l7eHhYZQtW9Zo2rSpMXnyZCMlJSXPNvk9LSEhIcFo1KiR4eXlZQQHBxv9+vUztm3blu+d8u+9955RuXJlw8PDw6hatarx0UcfGZ07dzbuvvtue5vcO8pfe+21PPvXZXf5G4ZhLFmyxGjYsKHh6elpeHt7Gy1atDB++OEH+/q///7beOqpp4w6deoYfn5+RqlSpYxq1aoZEyZMMM6dO2dvd/nTEr755hsjJibGKFeunP21adeunbFhw4arvrYRERH219VisRg+Pj5GtWrVjF69ehnfffddvttcfmyjRo0y6tevbwQEBBhWq9W44447jOeee844ceKEvU1mZqbRr18/Izg42LBYLA53W0syBg0aVKh95b4Xvv/+e6NXr15G6dKljVKlShnt2rUz9u7d67BtTk6OMXXqVOOOO+4wPD09jfr16xurV6/O87QEwzCMzz//3Khevbrh7u7usM/83kfZ2dnGq6++alStWtVwd3c3goKCjMcff9w4fPiwQ7umTZsatWrVynNMl//8ClLQ0xIWLlzo0C73fZjf0x7+Kb+nJfj7+xt33XWXMX36dOPvv//O02d+723DMIxffvnF6Natm1G2bFnD3d3dsNlsRvPmzY133nnH3iYzM9MYMWKEUa5cOcPT09O45557jCVLluQ5/o8//tiIjo42QkJCDA8PDyMsLMzo1q2bsWPHDod9zpw506hUqZLh5uZWqOM1DMPYvn270bt3b6NChQqGh4eH4e3tbdx9993Giy++6HDeKOy5oXfv3oa3t3ee/eT3PsnIyDBefPFFo0qVKoaHh4dRpkwZo3nz5kZCQoJDu48++sho2LCh4e3tbZQqVcq48847jSeeeMLYsmWLvU1B76WC5NaTO1mtViM0NNRo3bq18cYbbxhpaWl5tvntt9+MVq1aGb6+vkZAQIDxyCOPGIcOHcr3XDZ69GgjLCzMKFGihMNTLArzOh47dsyIjY01qlevbnh7exs+Pj5GnTp1jBkzZjg8dcYwLp0zo6OjDT8/P8NqtRoRERHGww8/bKxcudLe5krnFpiTxTAKcaszgKs6c+aMqlatqi5duui9995zdTkAANyWGJYAOCE5OVkvv/yyoqOjVaZMGR08eFAzZszQ2bNn9eyzz7q6PAAAbluEW8AJVqtVBw4c0MCBA3Xq1Cl5eXnpvvvu0zvvvKNatWq5ujwAAG5bDEsAAACAafAoMAAAAJgG4RYAAACmQbgFAACAaXBDmS59Z/bRo0fl6+tbrF9fCAAAgOJhGIbOnj2rsLCwK35hEuFWl77vPTw83NVlAAAA4CoOHz6s8uXLF7iecCvZv+f88OHD8vPzc3E1AAAAuFxaWprCw8Ptua0ghFvJPhTBz8+PcAsAAHATu9oQUm4oAwAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BZywfft2tW/fXhUqVFCpUqUUGBioRo0a6dNPP3VoFxsbK4vFkmeqXr26Q7v4+Ph82+VOr7zyyo08PAAAblk8LQFwwpkzZxQeHq5HH31U5cqV07lz5zRv3jz16tVLBw4c0Lhx4+xtS5UqpdWrVztsX6pUKYf59u3ba9OmTXn28+KLL2rFihV68MEHr8+BAABgMhbDMAxXF+FqaWlp8vf3V2pqKo8CwzW57777dPToUR06dEjSpSu3X3zxhdLT04vc17lz52Sz2XTXXXdpw4YNxV0qAAC3lMLmNYYlAMUoKChIJUsWzwciCxYsUHp6uvr161cs/QEAcDsg3ALXICcnRxcvXtTx48f19ttv67vvvtMLL7zg0CYjI0M2m01ubm4qX768Bg8erFOnTl217w8//FB+fn565JFHrlf5AACYDmNugWswcOBAvfvuu5IkDw8PvfnmmxowYIB9fd26dVW3bl1FRkZKktatW6cZM2Zo1apVSkxMlI+PT779/v7770pISNCAAQPk5eV1/Q8EAACTINwC12DMmDHq16+fUlJS9PXXX2vw4ME6d+6cRowYIUl67rnnHNq3atVKd999tx5++GG9//77edbn+vDDDyWJIQkAABQRN5SJG8pQfJ5++ml98MEHOnr0qIKDg/Ntk5OTIz8/P7Vv314LFizIs/7ChQsqX768QkNDtX379utcMQAAtwZuKANcoEGDBrp48aL++uuvK7YzDEMlSuT/6/fNN98oJSWFq7YAADiBcAsUozVr1qhEiRK64447CmzzxRdf6Pz587rvvvvyXf/hhx/K09NTjz322PUqEwAA02LMLeCEf/3rX/Lz81ODBg0UEhKiEydOaOHChVqwYIGef/55BQcH6+DBg+rZs6d69OihypUry2KxaN26dZo5c6Zq1aqV75XZo0ePavny5erevbsCAgJccGQAANzaCLeAExo1aqQ5c+bo448/1pkzZ+Tj46O6detq7ty5evzxxyVJfn5+CgkJ0fTp03Xs2DFlZ2crIiJCzzzzjMaMGSNvb+88/cbHxys7O5shCQAAOIkbysQNZQAAADc7bigDAADAbYdwCwAAANNgzC2c1qT9YFeXgNvExm9nuboEAMAtgiu3AAAAMA3CLQAAAEyDcAsAAADTcGm4nT17turUqSM/Pz/5+fmpUaNGWrZsmX19bGysLBaLw3T5tzplZmZqyJAhCgoKkre3tzp16qQjR47c6EMBAADATcCl4bZ8+fJ65ZVXtGXLFm3ZskXNmzdX586d9euvv9rbtG3bVklJSfZp6dKlDn0MHTpUixcv1vz587Vx40alp6erQ4cOys7OvtGHAwAAABdz6dMSOnbs6DD/8ssva/bs2dq8ebNq1aolSbJarbLZbPlun5qaqg8//FBz585Vy5YtJUmffvqpwsPDtXLlSrVp0+b6HgAAAABuKjfNmNvs7GzNnz9f586dU6NGjezL165dq7Jly6pq1arq37+/UlJS7Ou2bt2qCxcuqHXr1vZlYWFhioyMVEJCQoH7yszMVFpamsMEAACAW5/Lw+3OnTvl4+Mjq9Wqp556SosXL1bNmjUlSTExMZo3b55Wr16t119/XYmJiWrevLkyMzMlScnJyfLw8FBAQIBDnyEhIUpOTi5wn1OmTJG/v799Cg8Pv34HCAAAgBvG5V/iUK1aNW3fvl1nzpzRl19+qd69e2vdunWqWbOmunfvbm8XGRmp+vXrKyIiQt9++60eeuihAvs0DEMWi6XA9aNHj9awYcPs82lpaQRcAAAAE3B5uPXw8FDlypUlSfXr11diYqLeeOMNvfvuu3nahoaGKiIiQnv37pUk2Ww2ZWVl6fTp0w5Xb1NSUhQVFVXgPq1Wq6xWazEfCQAAAFzN5cMSLmcYhn3YweVOnjypw4cPKzQ0VJJUr149ubu7a8WKFfY2SUlJ2rVr1xXDLQAAAMzJpVdux4wZo5iYGIWHh+vs2bOaP3++1q5dq+XLlys9PV1xcXHq2rWrQkNDdeDAAY0ZM0ZBQUF68MEHJUn+/v7q27evhg8frjJlyigwMFAjRoxQ7dq17U9PAAAAwO3DpeH22LFj6tWrl5KSkuTv7686depo+fLlatWqlTIyMrRz50598sknOnPmjEJDQxUdHa0FCxbI19fX3seMGTNUsmRJdevWTRkZGWrRooXi4+Pl5ubmwiMDAACAK1gMwzBcXYSrpaWlyd/fX6mpqfLz83N1ObeMJu0Hu7oE3CY2fjvL1SUAAFyssHntphtzCwAAADiLcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANFwabmfPnq06derIz89Pfn5+atSokZYtW2ZfbxiG4uLiFBYWplKlSqlZs2b69ddfHfrIzMzUkCFDFBQUJG9vb3Xq1ElHjhy50YcCAACAm4BLw2358uX1yiuvaMuWLdqyZYuaN2+uzp072wPs1KlTNX36dM2aNUuJiYmy2Wxq1aqVzp49a+9j6NChWrx4sebPn6+NGzcqPT1dHTp0UHZ2tqsOCwAAAC5iMQzDcHUR/xQYGKjXXntNTz75pMLCwjR06FC98MILki5dpQ0JCdGrr76qAQMGKDU1VcHBwZo7d666d+8uSTp69KjCw8O1dOlStWnTplD7TEtLk7+/v1JTU+Xn53fdjs1smrQf7OoScJvY+O0sV5cAAHCxwua1m2bMbXZ2tubPn69z586pUaNG2r9/v5KTk9W6dWt7G6vVqqZNmyohIUGStHXrVl24cMGhTVhYmCIjI+1t8pOZmam0tDSHCQAAALc+l4fbnTt3ysfHR1arVU899ZQWL16smjVrKjk5WZIUEhLi0D4kJMS+Ljk5WR4eHgoICCiwTX6mTJkif39/+xQeHl7MRwUAAABXcHm4rVatmrZv367Nmzfr6aefVu/evfXbb7/Z11ssFof2hmHkWXa5q7UZPXq0UlNT7dPhw4ev7SAAAABwU3B5uPXw8FDlypVVv359TZkyRXXr1tUbb7whm80mSXmuwKakpNiv5tpsNmVlZen06dMFtsmP1Wq1P6EhdwIAAMCtz+Xh9nKGYSgzM1OVKlWSzWbTihUr7OuysrK0bt06RUVFSZLq1asnd3d3hzZJSUnatWuXvQ0AAABuHyVdufMxY8YoJiZG4eHhOnv2rObPn6+1a9dq+fLlslgsGjp0qCZPnqwqVaqoSpUqmjx5sry8vNSzZ09Jkr+/v/r27avhw4erTJkyCgwM1IgRI1S7dm21bNnSlYcGAAAAF3BpuD127Jh69eqlpKQk+fv7q06dOlq+fLlatWolSRo5cqQyMjI0cOBAnT59Wg0bNtT3338vX19fex8zZsxQyZIl1a1bN2VkZKhFixaKj4+Xm5ubqw4LAAAALnLTPefWFXjOrXN4zi1uFJ5zCwC45Z5zCwAAAFwrwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA03BpuJ0yZYruvfde+fr6qmzZsurSpYv27Nnj0CY2NlYWi8Vhuu+++xzaZGZmasiQIQoKCpK3t7c6deqkI0eO3MhDAQAAwE3ApeF23bp1GjRokDZv3qwVK1bo4sWLat26tc6dO+fQrm3btkpKSrJPS5cudVg/dOhQLV68WPPnz9fGjRuVnp6uDh06KDs7+0YeDgAAAFyspCt3vnz5cof5OXPmqGzZstq6daseeOAB+3Kr1SqbzZZvH6mpqfrwww81d+5ctWzZUpL06aefKjw8XCtXrlSbNm2u3wEAAADgpnJTjblNTU2VJAUGBjosX7t2rcqWLauqVauqf//+SklJsa/bunWrLly4oNatW9uXhYWFKTIyUgkJCfnuJzMzU2lpaQ4TAAAAbn03Tbg1DEPDhg1TkyZNFBkZaV8eExOjefPmafXq1Xr99deVmJio5s2bKzMzU5KUnJwsDw8PBQQEOPQXEhKi5OTkfPc1ZcoU+fv726fw8PDrd2AAAAC4YVw6LOGfBg8erB07dmjjxo0Oy7t3727/d2RkpOrXr6+IiAh9++23euihhwrszzAMWSyWfNeNHj1aw4YNs8+npaURcAEAAEzgprhyO2TIEH311Vdas2aNypcvf8W2oaGhioiI0N69eyVJNptNWVlZOn36tEO7lJQUhYSE5NuH1WqVn5+fwwQAAIBbn0vDrWEYGjx4sBYtWqTVq1erUqVKV93m5MmTOnz4sEJDQyVJ9erVk7u7u1asWGFvk5SUpF27dikqKuq61Q4AAICbj0uHJQwaNEifffaZ/ve//8nX19c+Rtbf31+lSpVSenq64uLi1LVrV4WGhurAgQMaM2aMgoKC9OCDD9rb9u3bV8OHD1eZMmUUGBioESNGqHbt2vanJwAAAOD24NJwO3v2bElSs2bNHJbPmTNHsbGxcnNz086dO/XJJ5/ozJkzCg0NVXR0tBYsWCBfX197+xkzZqhkyZLq1q2bMjIy1KJFC8XHx8vNze1GHg4AAABczGIYhuHqIlwtLS1N/v7+Sk1NZfxtETRpP9jVJeA2sfHbWa4uAQDgYoXNazfFDWUAAABAcSDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAArV69Wk8++aSqV68ub29vlStXTp07d9bWrVsd2m3cuFH9+vVTvXr1ZLVaZbFYdODAgTz9/fHHHxoxYoTq1aun0qVLKzAwUI0bN9YXX3xxg44ItyvCLQAA0OzZs3XgwAE9++yzWrp0qd544w2lpKTovvvu0+rVq+3tVq1apZUrV6pChQqKiooqsL/vv/9e3377rbp27aqFCxdq3rx5qlKlih555BG99NJLN+KQcJuyGIZhuLoIV0tLS5O/v79SU1Pl5+fn6nJuGU3aD3Z1CbhNbPx2lqtLAEwvJSVFZcuWdViWnp6uypUrKzIyUitXrpQk5eTkqESJS9fGpk2bpueff1779+9XxYoVHbY9ceKEypQpI4vF4rC8Q4cOWrNmjU6dOiWr1Xr9DgimU9i8xpVbAACQJ9hKko+Pj2rWrKnDhw/bl+UG26sJCgrKE2wlqUGDBjp//rxOnTrlfLHAFRBuAQBAvlJTU7Vt2zbVqlWr2Ppcs2aNgoOD8w3TQHFwKtxu27ZNO3futM//73//U5cuXTRmzBhlZWUVW3EAAMB1Bg0apHPnzmns2LHF0t8HH3ygtWvXaty4cXJzcyuWPoHLORVuBwwYoD/++EOS9Ndff6lHjx7y8vLSwoULNXLkyGItEAAA3Hjjx4/XvHnzNGPGDNWrV++a+1u2bJkGDRqkhx9+WEOGDCmGCoH8ORVu//jjD911112SpIULF+qBBx7QZ599pvj4eH355ZfFWR8AALjBJk6cqEmTJunll1/W4MHXfvPwd999p4ceekitWrXSvHnz8h2LCxQXp8KtYRjKycmRJK1cuVLt2rWTJIWHh+vEiRPFVx0AALihJk6cqLi4OMXFxWnMmDHX3N93332nLl26qGnTpvryyy/l4eFRDFUCBXMq3NavX1+TJk3S3LlztW7dOrVv316StH//foWEhBRrgQAA4Mb497//rbi4OI0bN04TJky45v6+//57denSRU2aNNGSJUt49BduiJLObDRz5kw99thjWrJkicaOHavKlStLkr744osrPtAZAADcnF5//XW9+OKLatu2rdq3b6/Nmzc7rL/vvvskScePH9e6deskyX5z+bJlyxQcHKzg4GA1bdpU0qVvMuvSpYtsNpvGjBmj7du3O/RXs2ZNni2P66JYv8Th77//lpubm9zd3YuryxuCL3FwDl/igBuFL3EArr9mzZrZQ2t+cuPC2rVrFR0dnW+bpk2bau3atZKkuLg4TZw4scD+1qxZo2bNmjldL24/hc1rTofbM2fO6IsvvtCff/6p559/XoGBgdq2bZtCQkJUrlw5pwt3BcKtcwi3uFEItwCAwuY1p4Yl7NixQy1atFDp0qV14MAB9e/fX4GBgVq8eLEOHjyoTz75xOnCAQAAAGc5FW6HDRumPn36aOrUqfL19bUvj4mJUc+ePYutOAAAbiQ+kcKNwidS149TT0tITEzUgAED8iwvV66ckpOTr7koAAAAwBlOhVtPT0+lpaXlWb5nzx4FBwdfc1EAAACAM5wKt507d9ZLL72kCxcuSJIsFosOHTqkUaNGqWvXrsVaIAAAAFBYToXbadOm6fjx4ypbtqwyMjLUtGlTVa5cWb6+vnr55ZeLu0YAAACgUJy6oczPz08bN27U6tWrtW3bNuXk5Oiee+5Ry5Yti7s+AAAAoNCcCre5mjdvrubNmxdXLQAAAMA1cWpYwjPPPKM333wzz/JZs2Zp6NCh11oTAAAA4BSnwu2XX36pxo0b51keFRWlL7744pqLAgAAAJzhVLg9efKk/P398yz38/PTiRMnrrkoAAAAwBlOhdvKlStr+fLleZYvW7ZMd9xxxzUXBQAAADjDqXA7bNgwjRw5UhMmTNC6deu0bt06vfjiixo1apSee+65QvczZcoU3XvvvfL19VXZsmXVpUsX7dmzx6GNYRiKi4tTWFiYSpUqpWbNmunXX391aJOZmakhQ4YoKChI3t7e6tSpk44cOeLMoQEAAOAW5lS4ffLJJ/X666/rww8/VHR0tKKjo/Xpp59q9uzZ6t+/f6H7WbdunQYNGqTNmzdrxYoVunjxolq3bq1z587Z20ydOlXTp0/XrFmzlJiYKJvNplatWuns2bP2NkOHDtXixYs1f/58bdy4Uenp6erQoYOys7OdOTwAAADcoiyGYRjX0sHx48dVqlQp+fj4XHMxuV8MsW7dOj3wwAMyDENhYWEaOnSoXnjhBUmXrtKGhITo1Vdf1YABA5Samqrg4GDNnTtX3bt3lyQdPXpU4eHhWrp0qdq0aXPV/aalpcnf31+pqany8/O75uO4XTRpP9jVJeA2sfHbWa4uAbcJzmu4UTivFV1h85pTV27/KTg4uFiCrSSlpqZKkgIDAyVJ+/fvV3Jyslq3bm1vY7Va1bRpUyUkJEiStm7dqgsXLji0CQsLU2RkpL3N5TIzM5WWluYwAQAA4NbnVLg9duyYevXqpbCwMJUsWVJubm4OkzMMw9CwYcPUpEkTRUZGSpKSk5MlSSEhIQ5tQ0JC7OuSk5Pl4eGhgICAAttcbsqUKfL397dP4eHhTtUMAACAm4tT31AWGxurQ4cOafz48QoNDZXFYrnmQgYPHqwdO3Zo48aNedZd3r9hGFfd55XajB49WsOGDbPPp6WlEXABAABMwKlwu3HjRm3YsEF33XVXsRQxZMgQffXVV1q/fr3Kly9vX26z2SRdujobGhpqX56SkmK/mmuz2ZSVlaXTp087XL1NSUlRVFRUvvuzWq2yWq3FUjsAAABuHk4NSwgPD9c13ocm6dLV1cGDB2vRokVavXq1KlWq5LC+UqVKstlsWrFihX1ZVlaW1q1bZw+u9erVk7u7u0ObpKQk7dq1q8BwCwAAAHNyKtzOnDlTo0aN0oEDB65p54MGDdKnn36qzz77TL6+vkpOTlZycrIyMjIkXRqOMHToUE2ePFmLFy/Wrl27FBsbKy8vL/Xs2VOS5O/vr759+2r48OFatWqVfv75Zz3++OOqXbu2WrZseU31AQAA4Nbi1LCE7t276/z587rzzjvl5eUld3d3h/WnTp0qVD+zZ8+WJDVr1sxh+Zw5cxQbGytJGjlypDIyMjRw4ECdPn1aDRs21Pfffy9fX197+xkzZqhkyZLq1q2bMjIy1KJFC8XHxzt9cxsAAABuTU6F25kzZxbLzgsztMFisSguLk5xcXEFtvH09NRbb72lt956q1jqAgAAwK3JqXDbu3fv4q4DAAAAuGZOf4nDn3/+qXHjxunRRx9VSkqKJGn58uX69ddfi604AAAAoCicCrfr1q1T7dq19eOPP2rRokVKT0+XJO3YsUMTJkwo1gIBAACAwnIq3I4aNUqTJk3SihUr5OHhYV8eHR2tTZs2FVtxAAAAQFE4FW537typBx98MM/y4OBgnTx58pqLAgAAAJzhVLgtXbq0kpKS8iz/+eefVa5cuWsuCgAAAHCGU+G2Z8+eeuGFF5ScnCyLxaKcnBz98MMPGjFihJ544onirhEAAAAoFKfC7csvv6wKFSqoXLlySk9PV82aNfXAAw8oKipK48aNK+4aAQAAgEIp8nNuDcPQ0aNH9f777+vf//63tm3bppycHN19992qUqXK9agRAAAAKBSnwm2VKlX066+/qkqVKrrjjjuuR10AAABAkRV5WEKJEiVUpUoVnooAAACAm45TY26nTp2q559/Xrt27SruegAAAACnFXlYgiQ9/vjjOn/+vOrWrSsPDw+VKlXKYf2pU6eKpTgAAACgKJwKtzNnzizmMgAAAIBrV+Rwe+HCBa1du1bjx4/nZjIAAADcVIo85tbd3V2LFy++HrUAAAAA18SpG8oefPBBLVmypJhLAQAAAK6NU2NuK1eurH//+99KSEhQvXr15O3t7bD+mWeeKZbiAAAAgKJwKtx+8MEHKl26tLZu3aqtW7c6rLNYLIRbAAAAuIRT4Xb//v3FXQcAAABwzZwacwsAAADcjJy6cvvkk09ecf1HH33kVDEAAADAtXAq3J4+fdph/sKFC9q1a5fOnDmj5s2bF0thAAAAQFE5FW7ze85tTk6OBg4cyBc7AAAAwGWKbcxtiRIl9Nxzz2nGjBnF1SUAAABQJMV6Q9mff/6pixcvFmeXAAAAQKE5NSxh2LBhDvOGYSgpKUnffvutevfuXSyFAQAAAEXlVLj9+eefHeZLlCih4OBgvf7661d9kgIAAABwvTgVbtesWVPcdQAAAADXzKkxt/v379fevXvzLN+7d68OHDhwrTUBAAAATnEq3MbGxiohISHP8h9//FGxsbHXWhMAAADgFKfC7c8//6zGjRvnWX7fffdp+/bt11oTAAAA4BSnwq3FYtHZs2fzLE9NTVV2dvY1FwUAAAA4w6lwe//992vKlCkOQTY7O1tTpkxRkyZNiq04AAAAoCicelrC1KlT9cADD6hatWq6//77JUkbNmxQWlqaVq9eXawFAgAAAIXl1JXbmjVraseOHerWrZtSUlJ09uxZPfHEE/r9998VGRlZ3DUCAAAAheLUlVtJCgsL0+TJk4uzFgAAAOCaOHXlds6cOVq4cGGe5QsXLtTHH398zUUBAAAAznAq3L7yyisKCgrKs7xs2bJczQUAAIDLOBVuDx48qEqVKuVZHhERoUOHDl1zUQAAAIAznAq3ZcuW1Y4dO/Is/+WXX1SmTJlrLgoAAABwhlPhtkePHnrmmWe0Zs0aZWdnKzs7W6tXr9azzz6rHj16FHeNAAAAQKE49bSESZMm6eDBg2rRooVKlrzURXZ2tnr37s2YWwAAALiMU+HWw8NDCxYs0IgRI7R//355eXmpdu3aioiIKO76AAAAgEIrcrg9c+aMxo4dqwULFuj06dOSpICAAPXo0UOTJk1S6dKli7tGAAAAoFCKFG5PnTqlRo0a6f/+7//02GOPqUaNGjIMQ7t371Z8fLxWrVqlhIQEBQQEXK96AQAAgAIVKdy+9NJL8vDw0J9//qmQkJA861q3bq2XXnpJM2bMKNYiAQAAgMIo0tMSlixZomnTpuUJtpJks9k0depULV68uNiKAwAAAIqiSOE2KSlJtWrVKnB9ZGSkkpOTr7koAAAAwBlFCrdBQUE6cOBAgev379/PlzgAAADAZYoUbtu2bauxY8cqKysrz7rMzEyNHz9ebdu2LbbiAAAAgKIoUridOHGi9uzZoypVqmjq1Kn66quv9NVXX+mVV15RlSpVtHv3bsXFxRW6v/Xr16tjx44KCwuTxWLRkiVLHNbHxsbKYrE4TPfdd59Dm8zMTA0ZMkRBQUHy9vZWp06ddOTIkaIcFgAAAEyiSE9LKF++vDZt2qSBAwdq9OjRMgxDkmSxWNSqVSvNmjVL4eHhhe7v3Llzqlu3rvr06aOuXbvm26Zt27aaM2eOfd7Dw8Nh/dChQ/X1119r/vz5KlOmjIYPH64OHTpo69atcnNzK8rhAQAA4BZX5C9xqFSpkpYtW6bTp09r7969kqTKlSsrMDCwyDuPiYlRTEzMFdtYrVbZbLZ816WmpurDDz/U3Llz1bJlS0nSp59+qvDwcK1cuVJt2rQpck0AAAC4dRVpWMI/BQQEqEGDBmrQoIFTwbaw1q5dq7Jly6pq1arq37+/UlJS7Ou2bt2qCxcuqHXr1vZlYWFhioyMVEJCQoF9ZmZmKi0tzWECAADArc/pcHsjxMTEaN68eVq9erVef/11JSYmqnnz5srMzJQkJScny8PDI883ooWEhFzxkWRTpkyRv7+/fSrKUAoAAADcvIo8LOFG6t69u/3fkZGRql+/viIiIvTtt9/qoYceKnA7wzBksVgKXD969GgNGzbMPp+WlkbABQAAMIGb+srt5UJDQxUREWEf62uz2ZSVlaXTp087tEtJScn3W9RyWa1W+fn5OUwAAAC49d1S4fbkyZM6fPiwQkNDJUn16tWTu7u7VqxYYW+TlJSkXbt2KSoqylVlAgAAwEVcOiwhPT1d+/bts8/v379f27dvV2BgoAIDAxUXF6euXbsqNDRUBw4c0JgxYxQUFKQHH3xQkuTv76++fftq+PDhKlOmjAIDAzVixAjVrl3b/vQEAAAA3D5cGm63bNmi6Oho+3zuONjevXtr9uzZ2rlzpz755BOdOXNGoaGhio6O1oIFC+Tr62vfZsaMGSpZsqS6deumjIwMtWjRQvHx8TzjFgAA4Dbk0nDbrFkz+xdB5Oe77767ah+enp5666239NZbbxVnaQAAALgF3VJjbgEAAIArIdwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA2Xhtv169erY8eOCgsLk8Vi0ZIlSxzWG4ahuLg4hYWFqVSpUmrWrJl+/fVXhzaZmZkaMmSIgoKC5O3trU6dOunIkSM38CgAAABws3BpuD137pzq1q2rWbNm5bt+6tSpmj59umbNmqXExETZbDa1atVKZ8+etbcZOnSoFi9erPnz52vjxo1KT09Xhw4dlJ2dfaMOAwAAADeJkq7ceUxMjGJiYvJdZxiGZs6cqbFjx+qhhx6SJH388ccKCQnRZ599pgEDBig1NVUffvih5s6dq5YtW0qSPv30U4WHh2vlypVq06ZNvn1nZmYqMzPTPp+WllbMRwYAAABXuGnH3O7fv1/Jyclq3bq1fZnValXTpk2VkJAgSdq6dasuXLjg0CYsLEyRkZH2NvmZMmWK/P397VN4ePj1OxAAAADcMDdtuE1OTpYkhYSEOCwPCQmxr0tOTpaHh4cCAgIKbJOf0aNHKzU11T4dPny4mKsHAACAK7h0WEJhWCwWh3nDMPIsu9zV2litVlmt1mKpDwAAADePm/bKrc1mk6Q8V2BTUlLsV3NtNpuysrJ0+vTpAtsAAADg9nHThttKlSrJZrNpxYoV9mVZWVlat26doqKiJEn16tWTu7u7Q5ukpCTt2rXL3gYAAAC3D5cOS0hPT9e+ffvs8/v379f27dsVGBioChUqaOjQoZo8ebKqVKmiKlWqaPLkyfLy8lLPnj0lSf7+/urbt6+GDx+uMmXKKDAwUCNGjFDt2rXtT08AAADA7cOl4XbLli2Kjo62zw8bNkyS1Lt3b8XHx2vkyJHKyMjQwIEDdfr0aTVs2FDff/+9fH197dvMmDFDJUuWVLdu3ZSRkaEWLVooPj5ebm5uN/x4AAAA4FoWwzAMVxfhamlpafL391dqaqr8/PxcXc4to0n7wa4uAbeJjd/m/0UvQHHjvIYbhfNa0RU2r920Y24BAACAoiLcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDQItwAAADANwi0AAABMg3ALAAAA0yDcAgAAwDRu6nAbFxcni8XiMNlsNvt6wzAUFxensLAwlSpVSs2aNdOvv/7qwooBAADgSjd1uJWkWrVqKSkpyT7t3LnTvm7q1KmaPn26Zs2apcTERNlsNrVq1Upnz551YcUAAABwlZs+3JYsWVI2m80+BQcHS7p01XbmzJkaO3asHnroIUVGRurjjz/W+fPn9dlnn7m4agAAALjCTR9u9+7dq7CwMFWqVEk9evTQX3/9JUnav3+/kpOT1bp1a3tbq9Wqpk2bKiEh4Yp9ZmZmKi0tzWECAADAre+mDrcNGzbUJ598ou+++07vv/++kpOTFRUVpZMnTyo5OVmSFBIS4rBNSEiIfV1BpkyZIn9/f/sUHh5+3Y4BAAAAN85NHW5jYmLUtWtX1a5dWy1bttS3334rSfr444/tbSwWi8M2hmHkWXa50aNHKzU11T4dPny4+IsHAADADXdTh9vLeXt7q3bt2tq7d6/9qQmXX6VNSUnJczX3clarVX5+fg4TAAAAbn23VLjNzMzU7t27FRoaqkqVKslms2nFihX29VlZWVq3bp2ioqJcWCUAAABcpaSrC7iSESNGqGPHjqpQoYJSUlI0adIkpaWlqXfv3rJYLBo6dKgmT56sKlWqqEqVKpo8ebK8vLzUs2dPV5cOAAAAF7ipw+2RI0f06KOP6sSJEwoODtZ9992nzZs3KyIiQpI0cuRIZWRkaODAgTp9+rQaNmyo77//Xr6+vi6uHAAAAK5wU4fb+fPnX3G9xWJRXFyc4uLibkxBAAAAuKndUmNuAQAAgCsh3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDdOE27fffluVKlWSp6en6tWrpw0bNri6JAAAANxgpgi3CxYs0NChQzV27Fj9/PPPuv/++xUTE6NDhw65ujQAAADcQKYIt9OnT1ffvn3Vr18/1ahRQzNnzlR4eLhmz57t6tIAAABwA5V0dQHXKisrS1u3btWoUaMclrdu3VoJCQn5bpOZmanMzEz7fGpqqiQpLS3t+hVqQhcvZLm6BNwm+N3EjcJ5DTcK57Wiy33NDMO4YrtbPtyeOHFC2dnZCgkJcVgeEhKi5OTkfLeZMmWKJk6cmGd5eHj4dakRwLXx93/f1SUAQLHivOa8s2fPyt/fv8D1t3y4zWWxWBzmDcPIsyzX6NGjNWzYMPt8Tk6OTp06pTJlyhS4DVAc0tLSFB4ersOHD8vPz8/V5QDANeO8hhvFMAydPXtWYWFhV2x3y4fboKAgubm55blKm5KSkudqbi6r1Sqr1eqwrHTp0terRCAPPz8//ggAMBXOa7gRrnTFNtctf0OZh4eH6tWrpxUrVjgsX7FihaKiolxUFQAAAFzhlr9yK0nDhg1Tr169VL9+fTVq1EjvvfeeDh06pKeeesrVpQEAAOAGMkW47d69u06ePKmXXnpJSUlJioyM1NKlSxUREeHq0gAHVqtVEyZMyDMsBgBuVZzXcLOxGFd7ngIAAABwi7jlx9wCAAAAuQi3AAAAMA3CLQAAAEyDcAu4UMWKFTVz5kxXlwEAkqQDBw7IYrFo+/btkqS1a9fKYrHozJkzLq0LKArCLZCP2NhYWSwW+1SmTBm1bdtWO3bsKNb9JCYm6l//+lex9gng9pJ7vsrv8ZcDBw6UxWJRbGysU31HRUUpKSmpUA/Ov9Hi4+P5Aibki3ALFKBt27ZKSkpSUlKSVq1apZIlS6pDhw7Fuo/g4GB5eXkVa58Abj/h4eGaP3++MjIy7Mv+/vtvff7556pQoYLT/Xp4eMhms/HV9LilEG6BAlitVtlsNtlsNt1111164YUXdPjwYR0/flyS9H//93/q3r27AgICVKZMGXXu3FkHDhywbx8bG6suXbpo2rRpCg0NVZkyZTRo0CBduHDB3ubyYQm///67mjRpIk9PT9WsWVMrV66UxWLRkiVLJP3/jwwXLVqk6OhoeXl5qW7dutq0adONeEkA3KTuueceVahQQYsWLbIvW7RokcLDw3X33Xfbly1fvlxNmjRR6dKlVaZMGXXo0EF//vlngf3mNyzh/fffV3h4uLy8vPTggw9q+vTpDldQ4+LidNddd2nu3LmqWLGi/P391aNHD509e7bQdVztXLd27Vr16dNHqamp9k/Y4uLiruEVhJkQboFCSE9P17x581S5cmWVKVNG58+fV3R0tHx8fLR+/Xpt3LhRPj4+atu2rbKysuzbrVmzRn/++afWrFmjjz/+WPHx8YqPj893Hzk5OerSpYu8vLz0448/6r333tPYsWPzbTt27FiNGDFC27dvV9WqVfXoo4/q4sWL1+PQAdwi+vTpozlz5tjnP/roIz355JMObc6dO6dhw4YpMTFRq1atUokSJfTggw8qJyenUPv44Ycf9NRTT+nZZ5/V9u3b1apVK7388st52v35559asmSJvvnmG33zzTdat26dXnnllSLXUdC5LioqSjNnzpSfn5/9E7YRI0YU5eWCmRkA8ujdu7fh5uZmeHt7G97e3oYkIzQ01Ni6dathGIbx4YcfGtWqVTNycnLs22RmZhqlSpUyvvvuO3sfERERxsWLF+1tHnnkEaN79+72+YiICGPGjBmGYRjGsmXLjJIlSxpJSUn29StWrDAkGYsXLzYMwzD2799vSDI++OADe5tff/3VkGTs3r272F8HADe/3r17G507dzaOHz9uWK1WY//+/caBAwcMT09P4/jx40bnzp2N3r1757ttSkqKIcnYuXOnYRj//xzz888/G4ZhGGvWrDEkGadPnzYMwzC6d+9utG/f3qGPxx57zPD397fPT5gwwfDy8jLS0tLsy55//nmjYcOGBR5DQXVc6Vw3Z84ch/0CubhyCxQgOjpa27dv1/bt2/Xjjz+qdevWiomJ0cGDB7V161bt27dPvr6+8vHxkY+PjwIDA/X33387fLRWq1Ytubm52edDQ0OVkpKS7/727Nmj8PBw2Ww2+7IGDRrk27ZOnToOfUoqsF8At4egoCC1b99eH3/8sebMmaP27dsrKCjIoc2ff/6pnj176o477pCfn58qVaokSTp06FCh9rFnz54856X8zlMVK1aUr6+vff7yc19h6+BcB2eUdHUBwM3K29tblStXts/Xq1dP/v7+ev/995WTk6N69epp3rx5ebYLDg62/9vd3d1hncViKfDjP8MwCn3Txj/7zd2msB8rAjCvJ598UoMHD5Yk/ec//8mzvmPHjgoPD9f777+vsLAw5eTkKDIy0mE41ZXkd54yDCNPu6ud+wpbB+c6OINwCxSSxWJRiRIllJGRoXvuuUcLFixQ2bJl5efnVyz9V69eXYcOHdKxY8cUEhIi6dKjwgCgsP457r9NmzYO606ePKndu3fr3Xff1f333y9J2rhxY5H6r169un766SeHZVu2bClSH8VRh3TpSQ7Z2dlF3g7mx7AEoACZmZlKTk5WcnKydu/erSFDhig9PV0dO3bUY489pqCgIHXu3FkbNmzQ/v37tW7dOj377LM6cuSIU/tr1aqV7rzzTvXu3Vs7duzQDz/8YL+hjMfwACgMNzc37d69W7t373YYEiXJ/mSX9957T/v27dPq1as1bNiwIvU/ZMgQLV26VNOnT9fevXv17rvvatmyZUU6RxVHHdKloQ/p6elatWqVTpw4ofPnzxe5D5gT4RYowPLlyxUaGqrQ0FA1bNhQiYmJWrhwoZo1ayYvLy+tX79eFSpU0EMPPaQaNWroySefVEZGhtNXct3c3LRkyRKlp6fr3nvvVb9+/TRu3DhJkqenZ3EeGgAT8/Pzy/c8VKJECc2fP19bt25VZGSknnvuOb322mtF6rtx48Z65513NH36dNWtW1fLly/Xc889V6RzVHHUIV36gomnnnpK3bt3V3BwsKZOnVrkPmBOFiO/wTIAbgo//PCDmjRpon379unOO+90dTkAkEf//v31+++/a8OGDa4uBZDEmFvgprJ48WL5+PioSpUq2rdvn5599lk1btyYYAvgpjFt2jS1atVK3t7eWrZsmT7++GO9/fbbri4LsCPcAjeRs2fPauTIkTp8+LCCgoLUsmVLvf76664uCwDsfvrpJ02dOlVnz57VHXfcoTfffFP9+vVzdVmAHcMSAAAAYBrcUAYAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCgItZLBYtWbLE1WUUydq1a2WxWHTmzBlXlwIADgi3AHCdxMbGymKxyGKxyN3dXSEhIWrVqpU++ugj5eTk2NslJSUpJibGhZUWXVRUlJKSkuTv7+/qUgDAAeEWAK6jtm3bKikpSQcOHNCyZcsUHR2tZ599Vh06dNDFixclSTabTVar1cWVFo2Hh4dsNpssFourSwEAB4RbALiOrFarbDabypUrp3vuuUdjxozR//73Py1btkzx8fGS8g5LeOGFF1S1alV5eXnpjjvu0Pjx43XhwgWHfidNmqSyZcvK19dX/fr106hRo3TXXXfZ18fGxqpLly6aNm2aQkNDVaZMGQ0aNMihn9OnT+uJJ55QQECAvLy8FBMTo71799rXHzx4UB07dlRAQIC8vb1Vq1YtLV26VFLeYQlXagsANxJfvwsAN1jz5s1Vt25dLVq0KN+vLfX19VV8fLzCwsK0c+dO9e/fX76+vho5cqQkad68eXr55Zf19ttvq3Hjxpo/f75ef/11VapUyaGfNWvWKDQ0VGvWrNG+ffvUvXt33XXXXerfv7+kSwF47969+uqrr+Tn56cXXnhB7dq102+//SZ3d3cNGjRIWVlZWr9+vby9vfXbb7/Jx8cn32MqSlsAuJ4ItwDgAtWrV9eOHTvyXTdu3Dj7vytWrKjhw4drwYIF9nD71ltvqW/fvurTp48k6cUXX9T333+v9PR0h34CAgI0a9Ysubm5qXr16mrfvr1WrVql/v3720PtDz/8oKioKEmXQnN4eLiWLFmiRx55RIcOHVLXrl1Vu3ZtSdIdd9xR4PEUpS0AXE8MSwAAFzAMo8Dxql988YWaNGkim80mHx8fjR8/XocOHbKv37Nnjxo0aOCwzeXzklSrVi25ubnZ50NDQ5WSkiJJ2r17t0qWLKmGDRva15cpU0bVqlXT7t27JUnPPPOMJk2apMaNG2vChAkFhvGitgWA64lwCwAusHv37jzDCCRp8+bN6tGjh2JiYvTNN9/o559/1tixY5WVleXQ7vJgbBhGnr7c3d3zbJP7lIb82ucuz+27X79++uuvv9SrVy/t3LlT9evX11tvvZXvdkVpCwDXE+EWAG6w1atXa+fOneratWuedT/88IMiIiI0duxY1a9fX1WqVNHBgwcd2lSrVk0//fSTw7ItW7YUqYaaNWvq4sWL+vHHH+3LTp48qT/++EM1atSwLwsPD9dTTz2lRYsWafjw4Xr//fcL7LMobQHgemHMLQBcR5mZmUpOTlZ2draOHTum5cuXa8qUKerQoYOeeOKJPO0rV66sQ4cOaf78+br33nv17bffavHixQ5thgwZov79+6t+/fqKiorSggULtGPHjiKNc61SpYo6d+6s/v37691335Wvr69GjRqlcuXKqXPnzpKkoUOHKiYmRlWrVtXp06e1evVqh+D7T0VpCwDXE+EWAK6j5cuXKzQ0VCVLllRAQIDq1q2rN998U71791aJEnk/POvcubOee+45DR48WJmZmWrfvr3Gjx+vuLg4e5vHHntMf/31l0aMGKG///5b3bp1U2xsbJ6ruVczZ84c+zN3s7Ky9MADD2jp0qX24QzZ2dkaNGiQjhw5Ij8/P7Vt21YzZszIt6+itAWA68liFDTwCgBwy2jVqpVsNpvmzp3r6lIAwKW4cgsAt5jz58/rnXfeUZs2beTm5qbPP/9cK1eu1IoVK1xdGgC4HFduAeAWk5GRoY4dO2rbtm3KzMxUtWrVNG7cOD300EOuLg0AXI5wCwAAANPgUWAAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0/h9FE4JVLYkY8QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count occurrences of diagnosis (Malignant vs. Benign)\n",
    "value_counts = breast_cancer_data_prelimtrain['Diagnosis'].value_counts()\n",
    "\n",
    "custom_names = ['Benign', 'Malignant']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = value_counts.plot(kind='bar', color='#3b4a6b')\n",
    "\n",
    "ax.set_xticklabels(custom_names)\n",
    "for i, v in enumerate(value_counts):\n",
    "    ax.text(i, v + 0.1, str(v), ha='center', va='bottom', fontsize=12, color='black')\n",
    "    \n",
    "plt.title('Diagnosis Distribution in Breast Cancer Dataset')\n",
    "plt.xlabel('Diagnosis')\n",
    "plt.ylabel('Occurrences')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c31059c0-ca46-4423-bab5-c3fdb9cb1bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>...</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074626</td>\n",
       "      <td>0.099770</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.096893</td>\n",
       "      <td>-0.012968</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.050080</td>\n",
       "      <td>0.044158</td>\n",
       "      <td>-0.022114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.079986</td>\n",
       "      <td>0.107187</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.023203</td>\n",
       "      <td>0.035174</td>\n",
       "      <td>-0.044224</td>\n",
       "      <td>-0.029866</td>\n",
       "      <td>-0.039769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius1</th>\n",
       "      <td>0.074626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.170581</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>-0.730029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture1</th>\n",
       "      <td>0.099770</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>-0.415185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter1</th>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>-0.742636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area1</th>\n",
       "      <td>0.096893</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>-0.708984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness1</th>\n",
       "      <td>-0.012968</td>\n",
       "      <td>0.170581</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.499316</td>\n",
       "      <td>-0.358560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness1</th>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.687382</td>\n",
       "      <td>-0.596534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity1</th>\n",
       "      <td>0.050080</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.514930</td>\n",
       "      <td>-0.696360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave_points1</th>\n",
       "      <td>0.044158</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>-0.776614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry1</th>\n",
       "      <td>-0.022114</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>0.438413</td>\n",
       "      <td>-0.330499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <td>-0.052511</td>\n",
       "      <td>-0.311631</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>-0.283110</td>\n",
       "      <td>0.584792</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051269</td>\n",
       "      <td>-0.205151</td>\n",
       "      <td>-0.231854</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>0.012838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius2</th>\n",
       "      <td>0.143048</td>\n",
       "      <td>0.679090</td>\n",
       "      <td>0.275869</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.301467</td>\n",
       "      <td>0.497473</td>\n",
       "      <td>0.631925</td>\n",
       "      <td>0.698050</td>\n",
       "      <td>0.303379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194799</td>\n",
       "      <td>0.719684</td>\n",
       "      <td>0.751548</td>\n",
       "      <td>0.141919</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>0.531062</td>\n",
       "      <td>0.094543</td>\n",
       "      <td>0.049559</td>\n",
       "      <td>-0.567134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture2</th>\n",
       "      <td>-0.007526</td>\n",
       "      <td>-0.097317</td>\n",
       "      <td>0.386358</td>\n",
       "      <td>-0.086761</td>\n",
       "      <td>-0.066280</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.076218</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.128053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409003</td>\n",
       "      <td>-0.102242</td>\n",
       "      <td>-0.083195</td>\n",
       "      <td>-0.073658</td>\n",
       "      <td>-0.092439</td>\n",
       "      <td>-0.068956</td>\n",
       "      <td>-0.119638</td>\n",
       "      <td>-0.128215</td>\n",
       "      <td>-0.045655</td>\n",
       "      <td>0.008303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter2</th>\n",
       "      <td>0.137331</td>\n",
       "      <td>0.674172</td>\n",
       "      <td>0.281673</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>0.296092</td>\n",
       "      <td>0.548905</td>\n",
       "      <td>0.660391</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.313893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200371</td>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.730713</td>\n",
       "      <td>0.130054</td>\n",
       "      <td>0.341919</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.109930</td>\n",
       "      <td>0.085433</td>\n",
       "      <td>-0.556141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area2</th>\n",
       "      <td>0.177742</td>\n",
       "      <td>0.735864</td>\n",
       "      <td>0.259845</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.800086</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.455653</td>\n",
       "      <td>0.617427</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.223970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196497</td>\n",
       "      <td>0.761213</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.125389</td>\n",
       "      <td>0.283257</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.538166</td>\n",
       "      <td>0.074126</td>\n",
       "      <td>0.017539</td>\n",
       "      <td>-0.548236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness2</th>\n",
       "      <td>0.096781</td>\n",
       "      <td>-0.222600</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>-0.202694</td>\n",
       "      <td>-0.166777</td>\n",
       "      <td>0.332375</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>0.187321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074743</td>\n",
       "      <td>-0.217304</td>\n",
       "      <td>-0.182195</td>\n",
       "      <td>0.314457</td>\n",
       "      <td>-0.055558</td>\n",
       "      <td>-0.058298</td>\n",
       "      <td>-0.102007</td>\n",
       "      <td>-0.107342</td>\n",
       "      <td>0.101480</td>\n",
       "      <td>0.067016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness2</th>\n",
       "      <td>0.033961</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.191975</td>\n",
       "      <td>0.250744</td>\n",
       "      <td>0.212583</td>\n",
       "      <td>0.318943</td>\n",
       "      <td>0.738722</td>\n",
       "      <td>0.670279</td>\n",
       "      <td>0.490424</td>\n",
       "      <td>0.421659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143003</td>\n",
       "      <td>0.260516</td>\n",
       "      <td>0.199371</td>\n",
       "      <td>0.227394</td>\n",
       "      <td>0.678780</td>\n",
       "      <td>0.639147</td>\n",
       "      <td>0.483208</td>\n",
       "      <td>0.277878</td>\n",
       "      <td>0.590973</td>\n",
       "      <td>-0.292999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity2</th>\n",
       "      <td>0.055239</td>\n",
       "      <td>0.194204</td>\n",
       "      <td>0.143293</td>\n",
       "      <td>0.228082</td>\n",
       "      <td>0.207660</td>\n",
       "      <td>0.248396</td>\n",
       "      <td>0.570517</td>\n",
       "      <td>0.691270</td>\n",
       "      <td>0.439167</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100241</td>\n",
       "      <td>0.226680</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>0.168481</td>\n",
       "      <td>0.484858</td>\n",
       "      <td>0.662564</td>\n",
       "      <td>0.440472</td>\n",
       "      <td>0.197788</td>\n",
       "      <td>0.439329</td>\n",
       "      <td>-0.253730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave_points2</th>\n",
       "      <td>0.078768</td>\n",
       "      <td>0.376169</td>\n",
       "      <td>0.163851</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.372320</td>\n",
       "      <td>0.380676</td>\n",
       "      <td>0.642262</td>\n",
       "      <td>0.683260</td>\n",
       "      <td>0.615634</td>\n",
       "      <td>0.393298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086741</td>\n",
       "      <td>0.394999</td>\n",
       "      <td>0.342271</td>\n",
       "      <td>0.215351</td>\n",
       "      <td>0.452888</td>\n",
       "      <td>0.549592</td>\n",
       "      <td>0.602450</td>\n",
       "      <td>0.143116</td>\n",
       "      <td>0.310655</td>\n",
       "      <td>-0.408042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry2</th>\n",
       "      <td>-0.017306</td>\n",
       "      <td>-0.104321</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>-0.081629</td>\n",
       "      <td>-0.072497</td>\n",
       "      <td>0.200774</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.095351</td>\n",
       "      <td>0.449137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077473</td>\n",
       "      <td>-0.103753</td>\n",
       "      <td>-0.110343</td>\n",
       "      <td>-0.012662</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.037119</td>\n",
       "      <td>-0.030413</td>\n",
       "      <td>0.389402</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.006522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension2</th>\n",
       "      <td>0.025725</td>\n",
       "      <td>-0.042641</td>\n",
       "      <td>0.054458</td>\n",
       "      <td>-0.005523</td>\n",
       "      <td>-0.019887</td>\n",
       "      <td>0.283607</td>\n",
       "      <td>0.507318</td>\n",
       "      <td>0.449301</td>\n",
       "      <td>0.257584</td>\n",
       "      <td>0.331786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.022736</td>\n",
       "      <td>0.170568</td>\n",
       "      <td>0.390159</td>\n",
       "      <td>0.379975</td>\n",
       "      <td>0.215204</td>\n",
       "      <td>0.111094</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>-0.077972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius3</th>\n",
       "      <td>0.082405</td>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.216574</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.093492</td>\n",
       "      <td>-0.776454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture3</th>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.219122</td>\n",
       "      <td>-0.456903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter3</th>\n",
       "      <td>0.079986</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.138957</td>\n",
       "      <td>-0.782914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area3</th>\n",
       "      <td>0.107187</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.079647</td>\n",
       "      <td>-0.733825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness3</th>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.617624</td>\n",
       "      <td>-0.421465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness3</th>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>-0.590998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity3</th>\n",
       "      <td>0.023203</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.686511</td>\n",
       "      <td>-0.659610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave_points3</th>\n",
       "      <td>0.035174</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>-0.793566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry3</th>\n",
       "      <td>-0.044224</td>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>-0.416294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension3</th>\n",
       "      <td>-0.029866</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.499316</td>\n",
       "      <td>0.687382</td>\n",
       "      <td>0.514930</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>0.438413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219122</td>\n",
       "      <td>0.138957</td>\n",
       "      <td>0.079647</td>\n",
       "      <td>0.617624</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>0.686511</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.323872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis</th>\n",
       "      <td>-0.039769</td>\n",
       "      <td>-0.730029</td>\n",
       "      <td>-0.415185</td>\n",
       "      <td>-0.742636</td>\n",
       "      <td>-0.708984</td>\n",
       "      <td>-0.358560</td>\n",
       "      <td>-0.596534</td>\n",
       "      <td>-0.696360</td>\n",
       "      <td>-0.776614</td>\n",
       "      <td>-0.330499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.456903</td>\n",
       "      <td>-0.782914</td>\n",
       "      <td>-0.733825</td>\n",
       "      <td>-0.421465</td>\n",
       "      <td>-0.590998</td>\n",
       "      <td>-0.659610</td>\n",
       "      <td>-0.793566</td>\n",
       "      <td>-0.416294</td>\n",
       "      <td>-0.323872</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ID   radius1  texture1  perimeter1     area1  \\\n",
       "ID                  1.000000  0.074626  0.099770    0.073159  0.096893   \n",
       "radius1             0.074626  1.000000  0.323782    0.997855  0.987357   \n",
       "texture1            0.099770  0.323782  1.000000    0.329533  0.321086   \n",
       "perimeter1          0.073159  0.997855  0.329533    1.000000  0.986507   \n",
       "area1               0.096893  0.987357  0.321086    0.986507  1.000000   \n",
       "smoothness1        -0.012968  0.170581 -0.023389    0.207278  0.177028   \n",
       "compactness1        0.000096  0.506124  0.236702    0.556936  0.498502   \n",
       "concavity1          0.050080  0.676764  0.302418    0.716136  0.685983   \n",
       "concave_points1     0.044158  0.822529  0.293464    0.850977  0.823269   \n",
       "symmetry1          -0.022114  0.147741  0.071401    0.183027  0.151293   \n",
       "fractal_dimension1 -0.052511 -0.311631 -0.076437   -0.261477 -0.283110   \n",
       "radius2             0.143048  0.679090  0.275869    0.691765  0.732562   \n",
       "texture2           -0.007526 -0.097317  0.386358   -0.086761 -0.066280   \n",
       "perimeter2          0.137331  0.674172  0.281673    0.693135  0.726628   \n",
       "area2               0.177742  0.735864  0.259845    0.744983  0.800086   \n",
       "smoothness2         0.096781 -0.222600  0.006614   -0.202694 -0.166777   \n",
       "compactness2        0.033961  0.206000  0.191975    0.250744  0.212583   \n",
       "concavity2          0.055239  0.194204  0.143293    0.228082  0.207660   \n",
       "concave_points2     0.078768  0.376169  0.163851    0.407217  0.372320   \n",
       "symmetry2          -0.017306 -0.104321  0.009127   -0.081629 -0.072497   \n",
       "fractal_dimension2  0.025725 -0.042641  0.054458   -0.005523 -0.019887   \n",
       "radius3             0.082405  0.969539  0.352573    0.969476  0.962746   \n",
       "texture3            0.064720  0.297008  0.912045    0.303038  0.287489   \n",
       "perimeter3          0.079986  0.965137  0.358040    0.970387  0.959120   \n",
       "area3               0.107187  0.941082  0.343546    0.941550  0.959213   \n",
       "smoothness3         0.010338  0.119616  0.077503    0.150549  0.123523   \n",
       "compactness3       -0.002968  0.413463  0.277830    0.455774  0.390410   \n",
       "concavity3          0.023203  0.526911  0.301025    0.563879  0.512606   \n",
       "concave_points3     0.035174  0.744214  0.295316    0.771241  0.722017   \n",
       "symmetry3          -0.044224  0.163953  0.105008    0.189115  0.143570   \n",
       "fractal_dimension3 -0.029866  0.007066  0.119205    0.051019  0.003738   \n",
       "Diagnosis          -0.039769 -0.730029 -0.415185   -0.742636 -0.708984   \n",
       "\n",
       "                    smoothness1  compactness1  concavity1  concave_points1  \\\n",
       "ID                    -0.012968      0.000096    0.050080         0.044158   \n",
       "radius1                0.170581      0.506124    0.676764         0.822529   \n",
       "texture1              -0.023389      0.236702    0.302418         0.293464   \n",
       "perimeter1             0.207278      0.556936    0.716136         0.850977   \n",
       "area1                  0.177028      0.498502    0.685983         0.823269   \n",
       "smoothness1            1.000000      0.659123    0.521984         0.553695   \n",
       "compactness1           0.659123      1.000000    0.883121         0.831135   \n",
       "concavity1             0.521984      0.883121    1.000000         0.921391   \n",
       "concave_points1        0.553695      0.831135    0.921391         1.000000   \n",
       "symmetry1              0.557775      0.602641    0.500667         0.462497   \n",
       "fractal_dimension1     0.584792      0.565369    0.336783         0.166917   \n",
       "radius2                0.301467      0.497473    0.631925         0.698050   \n",
       "texture2               0.068406      0.046205    0.076218         0.021480   \n",
       "perimeter2             0.296092      0.548905    0.660391         0.710650   \n",
       "area2                  0.246552      0.455653    0.617427         0.690299   \n",
       "smoothness2            0.332375      0.135299    0.098564         0.027653   \n",
       "compactness2           0.318943      0.738722    0.670279         0.490424   \n",
       "concavity2             0.248396      0.570517    0.691270         0.439167   \n",
       "concave_points2        0.380676      0.642262    0.683260         0.615634   \n",
       "symmetry2              0.200774      0.229977    0.178009         0.095351   \n",
       "fractal_dimension2     0.283607      0.507318    0.449301         0.257584   \n",
       "radius3                0.213120      0.535315    0.688236         0.830318   \n",
       "texture3               0.036072      0.248133    0.299879         0.292752   \n",
       "perimeter3             0.238853      0.590210    0.729565         0.855923   \n",
       "area3                  0.206718      0.509604    0.675987         0.809630   \n",
       "smoothness3            0.805324      0.565541    0.448822         0.452753   \n",
       "compactness3           0.472468      0.865809    0.754968         0.667454   \n",
       "concavity3             0.434926      0.816275    0.884103         0.752399   \n",
       "concave_points3        0.503053      0.815573    0.861323         0.910155   \n",
       "symmetry3              0.394309      0.510223    0.409464         0.375744   \n",
       "fractal_dimension3     0.499316      0.687382    0.514930         0.368661   \n",
       "Diagnosis             -0.358560     -0.596534   -0.696360        -0.776614   \n",
       "\n",
       "                    symmetry1  ...  texture3  perimeter3     area3  \\\n",
       "ID                  -0.022114  ...  0.064720    0.079986  0.107187   \n",
       "radius1              0.147741  ...  0.297008    0.965137  0.941082   \n",
       "texture1             0.071401  ...  0.912045    0.358040  0.343546   \n",
       "perimeter1           0.183027  ...  0.303038    0.970387  0.941550   \n",
       "area1                0.151293  ...  0.287489    0.959120  0.959213   \n",
       "smoothness1          0.557775  ...  0.036072    0.238853  0.206718   \n",
       "compactness1         0.602641  ...  0.248133    0.590210  0.509604   \n",
       "concavity1           0.500667  ...  0.299879    0.729565  0.675987   \n",
       "concave_points1      0.462497  ...  0.292752    0.855923  0.809630   \n",
       "symmetry1            1.000000  ...  0.090651    0.219169  0.177193   \n",
       "fractal_dimension1   0.479921  ... -0.051269   -0.205151 -0.231854   \n",
       "radius2              0.303379  ...  0.194799    0.719684  0.751548   \n",
       "texture2             0.128053  ...  0.409003   -0.102242 -0.083195   \n",
       "perimeter2           0.313893  ...  0.200371    0.721031  0.730713   \n",
       "area2                0.223970  ...  0.196497    0.761213  0.811408   \n",
       "smoothness2          0.187321  ... -0.074743   -0.217304 -0.182195   \n",
       "compactness2         0.421659  ...  0.143003    0.260516  0.199371   \n",
       "concavity2           0.342627  ...  0.100241    0.226680  0.188353   \n",
       "concave_points2      0.393298  ...  0.086741    0.394999  0.342271   \n",
       "symmetry2            0.449137  ... -0.077473   -0.103753 -0.110343   \n",
       "fractal_dimension2   0.331786  ... -0.003195   -0.001000 -0.022736   \n",
       "radius3              0.185728  ...  0.359921    0.993708  0.984015   \n",
       "texture3             0.090651  ...  1.000000    0.365098  0.345842   \n",
       "perimeter3           0.219169  ...  0.365098    1.000000  0.977578   \n",
       "area3                0.177193  ...  0.345842    0.977578  1.000000   \n",
       "smoothness3          0.426675  ...  0.225429    0.236775  0.209145   \n",
       "compactness3         0.473200  ...  0.360832    0.529408  0.438296   \n",
       "concavity3           0.433721  ...  0.368366    0.618344  0.543331   \n",
       "concave_points3      0.430297  ...  0.359755    0.816322  0.747419   \n",
       "symmetry3            0.699826  ...  0.233027    0.269493  0.209146   \n",
       "fractal_dimension3   0.438413  ...  0.219122    0.138957  0.079647   \n",
       "Diagnosis           -0.330499  ... -0.456903   -0.782914 -0.733825   \n",
       "\n",
       "                    smoothness3  compactness3  concavity3  concave_points3  \\\n",
       "ID                     0.010338     -0.002968    0.023203         0.035174   \n",
       "radius1                0.119616      0.413463    0.526911         0.744214   \n",
       "texture1               0.077503      0.277830    0.301025         0.295316   \n",
       "perimeter1             0.150549      0.455774    0.563879         0.771241   \n",
       "area1                  0.123523      0.390410    0.512606         0.722017   \n",
       "smoothness1            0.805324      0.472468    0.434926         0.503053   \n",
       "compactness1           0.565541      0.865809    0.816275         0.815573   \n",
       "concavity1             0.448822      0.754968    0.884103         0.861323   \n",
       "concave_points1        0.452753      0.667454    0.752399         0.910155   \n",
       "symmetry1              0.426675      0.473200    0.433721         0.430297   \n",
       "fractal_dimension1     0.504942      0.458798    0.346234         0.175325   \n",
       "radius2                0.141919      0.287103    0.380585         0.531062   \n",
       "texture2              -0.073658     -0.092439   -0.068956        -0.119638   \n",
       "perimeter2             0.130054      0.341919    0.418899         0.554897   \n",
       "area2                  0.125389      0.283257    0.385100         0.538166   \n",
       "smoothness2            0.314457     -0.055558   -0.058298        -0.102007   \n",
       "compactness2           0.227394      0.678780    0.639147         0.483208   \n",
       "concavity2             0.168481      0.484858    0.662564         0.440472   \n",
       "concave_points2        0.215351      0.452888    0.549592         0.602450   \n",
       "symmetry2             -0.012662      0.060255    0.037119        -0.030413   \n",
       "fractal_dimension2     0.170568      0.390159    0.379975         0.215204   \n",
       "radius3                0.216574      0.475820    0.573975         0.787424   \n",
       "texture3               0.225429      0.360832    0.368366         0.359755   \n",
       "perimeter3             0.236775      0.529408    0.618344         0.816322   \n",
       "area3                  0.209145      0.438296    0.543331         0.747419   \n",
       "smoothness3            1.000000      0.568187    0.518523         0.547691   \n",
       "compactness3           0.568187      1.000000    0.892261         0.801080   \n",
       "concavity3             0.518523      0.892261    1.000000         0.855434   \n",
       "concave_points3        0.547691      0.801080    0.855434         1.000000   \n",
       "symmetry3              0.493838      0.614441    0.532520         0.502528   \n",
       "fractal_dimension3     0.617624      0.810455    0.686511         0.511114   \n",
       "Diagnosis             -0.421465     -0.590998   -0.659610        -0.793566   \n",
       "\n",
       "                    symmetry3  fractal_dimension3  Diagnosis  \n",
       "ID                  -0.044224           -0.029866  -0.039769  \n",
       "radius1              0.163953            0.007066  -0.730029  \n",
       "texture1             0.105008            0.119205  -0.415185  \n",
       "perimeter1           0.189115            0.051019  -0.742636  \n",
       "area1                0.143570            0.003738  -0.708984  \n",
       "smoothness1          0.394309            0.499316  -0.358560  \n",
       "compactness1         0.510223            0.687382  -0.596534  \n",
       "concavity1           0.409464            0.514930  -0.696360  \n",
       "concave_points1      0.375744            0.368661  -0.776614  \n",
       "symmetry1            0.699826            0.438413  -0.330499  \n",
       "fractal_dimension1   0.334019            0.767297   0.012838  \n",
       "radius2              0.094543            0.049559  -0.567134  \n",
       "texture2            -0.128215           -0.045655   0.008303  \n",
       "perimeter2           0.109930            0.085433  -0.556141  \n",
       "area2                0.074126            0.017539  -0.548236  \n",
       "smoothness2         -0.107342            0.101480   0.067016  \n",
       "compactness2         0.277878            0.590973  -0.292999  \n",
       "concavity2           0.197788            0.439329  -0.253730  \n",
       "concave_points2      0.143116            0.310655  -0.408042  \n",
       "symmetry2            0.389402            0.078079   0.006522  \n",
       "fractal_dimension2   0.111094            0.591328  -0.077972  \n",
       "radius3              0.243529            0.093492  -0.776454  \n",
       "texture3             0.233027            0.219122  -0.456903  \n",
       "perimeter3           0.269493            0.138957  -0.782914  \n",
       "area3                0.209146            0.079647  -0.733825  \n",
       "smoothness3          0.493838            0.617624  -0.421465  \n",
       "compactness3         0.614441            0.810455  -0.590998  \n",
       "concavity3           0.532520            0.686511  -0.659610  \n",
       "concave_points3      0.502528            0.511114  -0.793566  \n",
       "symmetry3            1.000000            0.537848  -0.416294  \n",
       "fractal_dimension3   0.537848            1.000000  -0.323872  \n",
       "Diagnosis           -0.416294           -0.323872   1.000000  \n",
       "\n",
       "[32 rows x 32 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation Matrix\n",
    "corr = breast_cancer_data_prelimtrain.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e58716-84f6-4cda-b651-dfd317f5a232",
   "metadata": {},
   "source": [
    "## Model Testing and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2879b193-c3da-4db3-947a-4a9297070c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: (426, 30)\n",
      "Test Set Size: (143, 30)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = breast_cancer_data_prelimtrain.drop(columns=['ID', 'Diagnosis'], axis = 1)  # Features\n",
    "y = breast_cancer_data_prelimtrain['Diagnosis']  # Target variable\n",
    "\n",
    "# Split into train (75%) and test (25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Training Set Size:\", X_train.shape)\n",
    "print(\"Test Set Size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce56b86c-10d5-4b68-ba80-6525ea14bf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=3000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b4b6354-6907-4380-89d6-7357865d7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test,y_pred=y_pred)\n",
    "prec = precision_score(y_true=y_test,y_pred=y_pred)\n",
    "rec = recall_score(y_true=y_test,y_pred=y_pred)\n",
    "result = pd.DataFrame([[\"Logistic Regression\",acc,f1,prec,rec]],columns=['Model','Accuracy','F1 score', 'Precision score','Recall score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08df7662-670c-42b9-98b9-278473775bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.31%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36ed9224-9b67-4046-9887-021ede5b907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test,y_pred=y_pred)\n",
    "prec = precision_score(y_true=y_test,y_pred=y_pred)\n",
    "rec = recall_score(y_true=y_test,y_pred=y_pred)\n",
    "model_result = pd.DataFrame([[\"Decision Tree\",acc,f1,prec,rec]],columns=['Model','Accuracy','F1 score', 'Precision score','Recall score'])\n",
    "result = pd.concat([model_result,result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "434cd592-33bd-4bc7-bd88-d4133e3fd8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.20%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "443d18c1-1e64-459e-9f55-9e948763beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test,y_pred=y_pred)\n",
    "prec = precision_score(y_true=y_test,y_pred=y_pred)\n",
    "rec = recall_score(y_true=y_test,y_pred=y_pred)\n",
    "model_result = pd.DataFrame([[\"Random Forest\",acc,f1,prec,rec]],columns=['Model','Accuracy','F1 score', 'Precision score','Recall score'])\n",
    "result = pd.concat([model_result,result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "698f7fe3-141c-4671-b1ce-a29dcba12702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.10%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daa33b02-8a19-4618-9e49-b7a2a0de3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test,y_pred=y_pred)\n",
    "prec = precision_score(y_true=y_test,y_pred=y_pred)\n",
    "rec = recall_score(y_true=y_test,y_pred=y_pred)\n",
    "model_result = pd.DataFrame([[\"Support Vector Machine\",acc,f1,prec,rec]],columns=['Model','Accuracy','F1 score', 'Precision score','Recall score'])\n",
    "result = pd.concat([model_result,result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03871021-7458-45b8-84fe-b48d06457647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7434c5f7-9a6d-465b-847a-781c5fed1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test,y_pred=y_pred)\n",
    "prec = precision_score(y_true=y_test,y_pred=y_pred)\n",
    "rec = recall_score(y_true=y_test,y_pred=y_pred)\n",
    "model_result = pd.DataFrame([[\"K Nearest Neighbors\",acc,f1,prec,rec]],columns=['Model','Accuracy','F1 score', 'Precision score','Recall score'])\n",
    "result = pd.concat([model_result,result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46daa5e7-9e0f-4654-9efc-37afff01b0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.80%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25883ed7-0cd6-433b-afb1-6383f060f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test,y_pred=y_pred)\n",
    "prec = precision_score(y_true=y_test,y_pred=y_pred)\n",
    "rec = recall_score(y_true=y_test,y_pred=y_pred)\n",
    "model_result = pd.DataFrame([[\"XGBoost\",acc,f1,prec,rec]],columns=['Model','Accuracy','F1 score', 'Precision score','Recall score'])\n",
    "result = pd.concat([model_result,result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc1762c1-9ca7-40dc-a179-1612c792f74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fcdb8e8-28e3-41ff-8472-32ded69c2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true=y_test,y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test,y_pred=y_pred)\n",
    "prec = precision_score(y_true=y_test,y_pred=y_pred)\n",
    "rec = recall_score(y_true=y_test,y_pred=y_pred)\n",
    "model_result = pd.DataFrame([[\"MLP (Neural Network)\",acc,f1,prec,rec]],columns=['Model','Accuracy','F1 score', 'Precision score','Recall score'])\n",
    "result = pd.concat([model_result,result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bc42955-b6c9-45d1-ae65-ef4e88b506d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision score</th>\n",
       "      <th>Recall score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP (Neural Network)</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.910112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.966292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.972376</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.988764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.961749</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.988764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.988764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.910112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.977528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  F1 score  Precision score  Recall score\n",
       "0    MLP (Neural Network)  0.937063  0.947368         0.987805      0.910112\n",
       "1                 XGBoost  0.958042  0.966292         0.966292      0.966292\n",
       "2     K Nearest Neighbors  0.965035  0.972376         0.956522      0.988764\n",
       "3  Support Vector Machine  0.951049  0.961749         0.936170      0.988764\n",
       "4           Random Forest  0.972028  0.977778         0.967033      0.988764\n",
       "5           Decision Tree  0.923077  0.936416         0.964286      0.910112\n",
       "6     Logistic Regression  0.965035  0.972067         0.966667      0.977528"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2aba0-8c8d-4a3a-9dbd-e218e8616aa5",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b87caa4-4bd8-486a-af03-290dcf207a5f",
   "metadata": {},
   "source": [
    "Two highest performing models: 1. Random Forest 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "648932d3-c034-4176-bc4d-e42e670ed36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 144 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "96 fits failed out of a total of 288.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "68 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94600939 0.95539906 0.94600939 0.9342723  0.94366197 0.94835681\n",
      " 0.94600939 0.94131455 0.94600939 0.93661972 0.94366197 0.94131455\n",
      " 0.95070423 0.94835681 0.94835681 0.9342723  0.94835681 0.94600939\n",
      " 0.94835681 0.94131455 0.94366197 0.94131455 0.9342723  0.94131455\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94366197 0.94131455 0.94835681 0.93896714 0.94366197 0.93661972\n",
      " 0.94366197 0.94366197 0.94366197 0.94131455 0.93896714 0.94366197\n",
      " 0.95305164 0.93896714 0.94600939 0.94131455 0.94600939 0.94131455\n",
      " 0.94366197 0.95539906 0.95070423 0.93661972 0.93661972 0.94366197\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95305164 0.95539906 0.95305164 0.94131455 0.94131455 0.93661972\n",
      " 0.94131455 0.94131455 0.94600939 0.94366197 0.94131455 0.94131455\n",
      " 0.95305164 0.95539906 0.95070423 0.95070423 0.93896714 0.93896714\n",
      " 0.95070423 0.94131455 0.94366197 0.94366197 0.93896714 0.94366197\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94600939 0.94366197 0.95070423 0.94131455 0.94366197 0.94366197\n",
      " 0.94835681 0.94600939 0.94835681 0.94366197 0.94366197 0.94131455\n",
      " 0.93661972 0.94835681 0.94366197 0.93896714 0.93661972 0.94366197\n",
      " 0.94131455 0.93896714 0.94835681 0.94600939 0.94835681 0.94131455]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best score: 0.9553990610328639\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter testing for random forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b872c64-8793-48b7-89d8-a484b9f13f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Score: 0.962435020519836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "270 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.91767442 0.92946648 0.89655267        nan        nan        nan\n",
      " 0.91767442 0.92711354 0.90596443        nan        nan        nan\n",
      " 0.91767442 0.92711354 0.91067031        nan        nan        nan\n",
      " 0.91532148 0.92002736 0.89419973        nan        nan        nan\n",
      " 0.91532148 0.92954856 0.90596443        nan        nan        nan\n",
      " 0.91532148 0.93425445 0.91067031        nan        nan        nan\n",
      " 0.92949384 0.92481532 0.89655267        nan        nan        nan\n",
      " 0.92949384 0.92478796 0.90596443        nan        nan        nan\n",
      " 0.92949384 0.92949384 0.91067031        nan        nan        nan\n",
      " 0.94829001 0.94128591 0.89655267        nan        nan        nan\n",
      " 0.94829001 0.95064295 0.90596443        nan        nan        nan\n",
      " 0.94829001 0.94829001 0.91067031        nan        nan        nan\n",
      " 0.9553762  0.94125855 0.89655267        nan        nan        nan\n",
      " 0.9553762  0.95302326 0.90596443        nan        nan        nan\n",
      " 0.9553762  0.9553762  0.91067031        nan        nan        nan\n",
      " 0.96243502 0.94125855 0.89655267        nan        nan        nan\n",
      " 0.96243502 0.95067031 0.90596443        nan        nan        nan\n",
      " 0.96243502 0.9553762  0.91067031        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter testing for logistic regression model\n",
    "                        \n",
    "logreg = LogisticRegression(max_iter=3000)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],          \n",
    "    'solver': ['liblinear', 'lbfgs', 'saga'],    \n",
    "    'penalty': ['l2', 'elasticnet'],     \n",
    "    'max_iter': [100, 200, 300]                     \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
